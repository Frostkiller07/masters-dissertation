# -*- coding: utf-8 -*-
"""Dissertation_40423943.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1miTr9F-igc-aHLUfJFN9edN1o0rvjCoZ

**Data Preprocessing**
"""

import pandas as pd

file_path = 'C:/projects_1/city_day.csv'
city_air_quality_df = pd.read_csv(file_path)

# Display the first few rows of the dataset
print(city_air_quality_df.head())

# fetch info of the dataset
print(city_air_quality_df.info())

# fetch Summary for numerical columns of data
air_qual_summary = city_air_quality_df.describe()
print(air_qual_summary)

# format Date parameter to datetime
city_air_quality_df['Date'] = pd.to_datetime(city_air_quality_df['Date'])

# check the datatpye
print(city_air_quality_df['Date'].dtype)

# fetch an count null values in each column
null_summary = city_air_quality_df.isnull().sum()

null_summary

# replace null values with their mean values
city_air_quality_df['PM2.5'].fillna(city_air_quality_df['PM2.5'].mean().round(2),inplace = True )
city_air_quality_df['PM10'].fillna(city_air_quality_df['PM10'].mean().round(2),inplace = True )
city_air_quality_df['NO'].fillna(city_air_quality_df['NO'].mean().round(2),inplace = True )
city_air_quality_df['NO2'].fillna(city_air_quality_df['NO2'].mean().round(2),inplace = True )
city_air_quality_df['NOx'].fillna(city_air_quality_df['NOx'].mean().round(2),inplace = True )
city_air_quality_df['NH3'].fillna(city_air_quality_df['NH3'].mean().round(2),inplace = True )
city_air_quality_df['CO'].fillna(city_air_quality_df['CO'].mean().round(2),inplace = True )
city_air_quality_df['SO2'].fillna(city_air_quality_df['SO2'].mean().round(2),inplace = True )
city_air_quality_df['O3'].fillna(city_air_quality_df['O3'].mean().round(2),inplace = True )
city_air_quality_df['Benzene'].fillna(city_air_quality_df['Benzene'].mean().round(2),inplace = True )
city_air_quality_df['Toluene'].fillna(city_air_quality_df['Toluene'].mean().round(2),inplace = True )
city_air_quality_df['Xylene'].fillna(city_air_quality_df['Xylene'].mean().round(2),inplace = True )
city_air_quality_df['AQI'].fillna(city_air_quality_df['AQI'].mean().round(2),inplace = True )

#check values of AQI_Bucket column
city_air_quality_df['AQI_Bucket'].unique()

# fetch Null values count for AQI range of 0 - 50
aqi_good=city_air_quality_df[(city_air_quality_df.AQI >0)&(city_air_quality_df.AQI <=50)]
aqi_good["AQI_Bucket"].isnull().sum()

# fetch Null values count for AQI range of 51 - 100
aqi_satisfact=city_air_quality_df[(city_air_quality_df.AQI >50)&(city_air_quality_df.AQI <=100)]
aqi_satisfact["AQI_Bucket"].isnull().sum()

# fetch Null values count for AQI range of 101 - 200
aqi_moderate=city_air_quality_df[(city_air_quality_df.AQI >100)&(city_air_quality_df.AQI <=200)]
aqi_moderate["AQI_Bucket"].isnull().sum()

# fetch Null values count for AQI range of 201 - 300
aqi_poor=city_air_quality_df[(city_air_quality_df.AQI >200)&(city_air_quality_df.AQI <=300)]
aqi_poor["AQI_Bucket"].isnull().sum()

# fetch Null values count for AQI range of 301 - 400
aqi_verypoor=city_air_quality_df[(city_air_quality_df.AQI >300)&(city_air_quality_df.AQI <=400)]
aqi_verypoor["AQI_Bucket"].isnull().sum()

# fetch Null values count for AQI range of above 400 .
aqi_severe=city_air_quality_df[(city_air_quality_df.AQI >400)]
aqi_severe["AQI_Bucket"].isnull().sum()

def assign_aqi_bucket(aqi):
    if 0 < aqi <= 50:
        return 'Good'
    elif 51 <= aqi <= 100:
        return 'Satisfactory'
    elif 101 <= aqi <= 200:
        return 'Moderate'
    elif 201 <= aqi <= 300:
        return 'Poor'
    elif 301 <= aqi <= 400:
        return 'Very Poor'
    elif aqi > 400:
        return 'Severe'
    else:
        return None  # For AQI values that might be out of the expected range or undefined

# Apply the function to fill missing AQI_Bucket based on AQI
city_air_quality_df['AQI_Bucket'] = city_air_quality_df.apply(
    lambda row: assign_aqi_bucket(row['AQI']) if pd.isnull(row['AQI_Bucket']) else row['AQI_Bucket'],
    axis=1
)

# Define a function to check if AQI_Bucket matches AQI ranges
def check_aqi_bucket(row):
    buckets = {
        'Good': (0, 50),
        'Satisfactory': (51, 100),
        'Moderate': (101, 200),
        'Poor': (201, 300),
        'Very Poor': (301, 400),
        'Severe': (401, float('inf'))
    }
    for key, (low, high) in buckets.items():
        if low <= row['AQI'] <= high:
            return key == row['AQI_Bucket']
    return False  # Returns False if no range fits, indicating an error

# Apply the check across the dataset
incorrect_buckets = city_air_quality_df[~city_air_quality_df.apply(check_aqi_bucket, axis=1)]
print("Incorrect AQI Bucket entries:", len(incorrect_buckets))

#Missing Values Check
print(city_air_quality_df.isnull().sum())

"""**Exploratory Data Analysis**"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(city_air_quality_df['AQI'], bins=30, kde=True)
plt.title('Frequency Distribution of AQI')
plt.xlabel('AQI')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# only select  pollutants params
params_predictors = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx','NH3', 'CO', 'SO2', 'O3']

# Plot boxplot
plt.figure(figsize=(12, 8))
sns.boxplot(data=city_air_quality_df[params_predictors])
plt.title('Boxplot of Different Pollutants')
plt.ylabel('Concentration')
plt.xticks(rotation=45)
plt.show()

# select specific city
city_value = city_air_quality_df[city_air_quality_df['City'] == 'Ahmedabad']

# Plot PM2.5 levels over time
plt.figure(figsize=(14, 7))
plt.plot(city_value['Date'], city_value['PM2.5'], label='PM2.5', color='blue')
plt.title('PM2.5 Levels Over Time in Ahmedabad')
plt.xlabel('Date')
plt.ylabel('PM2.5')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(14, 7))
sns.boxplot(x=city_air_quality_df['Date'].dt.year, y='AQI', data=city_air_quality_df)
plt.xlabel('Year')
plt.ylabel('AQI')
plt.title('Distribution of AQI by Year')
plt.show()

plt.figure(figsize=(12, 8))
city_air_quality_df.boxplot(column='AQI', by='City', grid=False, rot=90)
plt.title('Boxplot of AQI by City')
plt.suptitle('')
plt.xlabel('City')
plt.ylabel('AQI')
plt.show()

plt.figure(figsize=(10, 6))
city_air_quality_df['AQI_Bucket'].value_counts().plot(kind='bar')
plt.title('Distribution of AQI Buckets')
plt.xlabel('AQI Bucket')
plt.ylabel('Frequency')
plt.show()

# correlation analysis
num_params = city_air_quality_df.select_dtypes(include=['float64']).columns
cor_matrix = city_air_quality_df[num_params].corr()
cor_matrix

# heatmap of correlation matrix
plt.figure(figsize=(12, 8))
sns.heatmap(cor_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix')
plt.show()

import seaborn as sns

# Boxplot to visualize regional variations
plt.figure(figsize=(10, 6))
sns.boxplot(x='City', y='AQI', data=city_air_quality_df)
plt.xticks(rotation=90)
plt.title('Regional Variations in AQI')
plt.xlabel('City')
plt.ylabel('AQI')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Set up the matplotlib figure
plt.figure(figsize=(18, 12))

# List of pollutants
pollutants = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx','NH3', 'CO', 'SO2', 'O3']

# Create a subplot for each pollutant
for i, pollutant in enumerate(pollutants, 1):
    plt.subplot(3, 3, i)
    sns.regplot(x=pollutant, y='AQI', data=city_air_quality_df, scatter_kws={'alpha':0.3}, line_kws={'color':'red'})
    plt.title(f'Relationship between {pollutant} and AQI')
    plt.xlabel(pollutant)
    plt.ylabel('AQI')

# Adjust layout
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Create a time-series plot of AQI over time
plt.figure(figsize=(12, 6))
sns.lineplot(x='Date', y='AQI', data=city_air_quality_df, ci=None)
plt.title('AQI Levels Over Time')
plt.xlabel('Date')
plt.ylabel('AQI')
plt.grid(True)
plt.show()

import pandas as pd

# Assuming 'Date' is already converted to datetime in your DataFrame
city_air_quality_df['DayOfWeek'] = city_air_quality_df['Date'].dt.day_name()
city_air_quality_df['Month'] = city_air_quality_df['Date'].dt.month
city_air_quality_df['Season'] = city_air_quality_df['Date'].dt.month % 12 // 3 + 1

# Mapping month numbers to season names
seasons = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}
city_air_quality_df['Season'] = city_air_quality_df['Season'].map(seasons)

from statsmodels.tsa.seasonal import seasonal_decompose
import matplotlib.pyplot as plt

# Resample the data by monthly averages
monthly_aqi = city_air_quality_df.resample('M', on='Date')['AQI'].mean()

# Decompose the time series
result = seasonal_decompose(monthly_aqi, model='additive')

# Plot the decomposition
result.plot()
plt.show()

import seaborn as sns

# Group data by DayOfWeek and calculate mean AQI
weekday_aqi = city_air_quality_df.groupby('DayOfWeek')['AQI'].mean().reindex([
    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'
])

# Plotting
plt.figure(figsize=(10, 6))
sns.barplot(x=weekday_aqi.index, y=weekday_aqi.values)
plt.title('Average AQI by Day of the Week')
plt.ylabel('Average AQI')
plt.xlabel('Day of the Week')
plt.xticks(rotation=45)
plt.show()

# Group data by Season and calculate mean AQI
seasonal_aqi = city_air_quality_df.groupby('Season')['AQI'].mean()

# Plotting
plt.figure(figsize=(10, 6))
seasonal_aqi.plot(kind='bar', color='skyblue')
plt.title('Average AQI by Season')
plt.ylabel('Average AQI')
plt.xlabel('Season')
plt.xticks(rotation=45)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Group data by City and calculate mean AQI
city_mean_aqi = city_air_quality_df.groupby('City')['AQI'].mean().sort_values()

# Plotting
plt.figure(figsize=(12, 10))
sns.barplot(x=city_mean_aqi.values, y=city_mean_aqi.index, palette='viridis')
plt.title('Average AQI by City')
plt.xlabel('Average AQI')
plt.ylabel('City')
plt.show()

plt.figure(figsize=(14, 8))
sns.boxplot(x='AQI', y='City', data=city_air_quality_df, palette='coolwarm')
plt.title('AQI Distribution by City')
plt.xlabel('AQI')
plt.ylabel('City')
plt.show()

import scipy.stats as stats

# ANOVA test
f_val, p_val = stats.f_oneway(*[group['AQI'].values for name, group in city_air_quality_df.groupby('City')])
print('ANOVA test results: F-value =', f_val, ', P-value =', p_val)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Assuming 'city_air_quality_df' is already loaded and cleaned
X = city_air_quality_df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3']]  # predictors
y = city_air_quality_df['AQI']  # target

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Initialize and train the Linear Regression model
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

# Predict on the testing set
y_pred = lin_reg.predict(X_test)

# Calculate metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)


print(f"Mean Squared Error: {mse}")
print(f"Root Mean Squared Error: {rmse}")
print(f"R^2 Score: {r2}")
print(f"Mean Absolute Error: {mae}")

# Get the coefficients from the model
coefficients = lin_reg.coef_

# Create a DataFrame to view the coefficients along with feature names
features = X.columns
coef_df = pd.DataFrame(list(zip(features, coefficients)), columns=['Feature', 'Coefficient'])

# Sort by the absolute values of coefficients in descending order to see the top predictors
coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()
top_predictors = coef_df.sort_values(by='Abs_Coefficient', ascending=False)

print(top_predictors)

import numpy as np
import pandas as pd
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split


X = city_air_quality_df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx','NH3', 'CO', 'SO2', 'O3']]  # predictors
y = city_air_quality_df['AQI'] # target

# Split the dataset into training and testing sets first
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize and train the SVM model
svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)
svr.fit(X_train_scaled, y_train)

# Predict on the testing set
y_pred = svr.predict(X_test_scaled)

# Calculate metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)


print(f"Mean Squared Error: {mse}")
print(f"Root Mean Squared Error: {rmse}")
print(f"R^2 Score: {r2}")
print(f"Mean Absolute Error: {mae}")

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt


# Select features and target
X = city_air_quality_df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3']]  # predictors
y = city_air_quality_df['AQI']  # target

# split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and fit the Random Forest model
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predict on the testing set
y_pred = rf.predict(X_test)

# Calculate metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)


print(f"Mean Squared Error: {mse}")
print(f"Root Mean Squared Error: {rmse}")
print(f"R^2 Score: {r2}")
print(f"Mean Absolute Error: {mae}")

# Feature Importance
importances = rf.feature_importances_
sorted_indices = np.argsort(importances)[::-1]

# Plotting
plt.title('Feature Importance')
plt.bar(range(X.shape[1]), importances[sorted_indices], align='center')
plt.xticks(range(X.shape[1]), X.columns[sorted_indices], rotation=90)
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
from sklearn.linear_model import Lasso
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score


X = city_air_quality_df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3','CO', 'SO2', 'O3']]  # predictors
y = city_air_quality_df['AQI']

# spit the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features (important for regularization)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define the Lasso Regression model
# alpha is the regularization parameter (commonly known as lambda in statistical models)
lasso = Lasso(alpha=0.1, max_iter=10000, random_state=42)

# Fit the model
lasso.fit(X_train_scaled, y_train)

# Predict on the testing set
y_pred = lasso.predict(X_test_scaled)

# Calculate metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)


# Output the coefficients from the model
coefficients = lasso.coef_
features = X.columns

# Create a DataFrame to view the coefficients of each feature
coef_df = pd.DataFrame(list(zip(features, coefficients)), columns=['Feature', 'Coefficient'])
coef_df = coef_df.sort_values(by='Coefficient', key=abs, ascending=False)  # Sorting by absolute value of coefficients

print("Model performance:")
print(f"Mean Squared Error: {mse}")
print(f"Root Mean Squared Error: {rmse}")
print(f"R^2 Score: {r2}")
print(f"Mean Absolute Error: {mae}")
print("\nModel coefficients:")
print(coef_df)

from sklearn.linear_model import LassoCV

# Create a LassoCV object to find the optimal alpha
lasso_cv = LassoCV(alphas=np.logspace(-6, 6, 13), cv=5, max_iter=10000, random_state=42)
lasso_cv.fit(X_train_scaled, y_train)

# Use the best alpha found
best_lasso = Lasso(alpha=lasso_cv.alpha_, max_iter=10000)
best_lasso.fit(X_train_scaled, y_train)
y_pred = best_lasso.predict(X_test_scaled)

# Evaluate and print the results
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Optimal alpha: {lasso_cv.alpha_}")
print(f"Mean Squared Error: {mse:.2f}")
print(f"R² Score: {r2:.2f}")

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load your dataset (assuming it's a DataFrame named 'city_air_quality_df')
X = city_air_quality_df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx','NH3', 'CO', 'SO2', 'O3']]  # predictors
y = city_air_quality_df['AQI_Bucket']  # categorical target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train Logistic Regression model
log_reg = LogisticRegression(max_iter=1000, random_state=42)
log_reg.fit(X_train_scaled, y_train)

# Predict on the testing set
y_pred = log_reg.predict(X_test_scaled)

# Evaluate the model
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

import numpy as np
from sklearn.model_selection import cross_val_score, KFold
from sklearn.linear_model import LinearRegression, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# Data preparation
X = city_air_quality_df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx','NH3', 'CO', 'SO2', 'O3']]  # predictors
y = city_air_quality_df['AQI']  # target

# Define the models
models = {
    'Linear Regression': LinearRegression(),
    'SVR': make_pipeline(StandardScaler(), SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'Lasso Regression': make_pipeline(StandardScaler(), Lasso(alpha=0.1, max_iter=10000))
}

# Define k-fold cross-validation setup
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Perform k-fold cross-validation and store results
results = {}
for name, model in models.items():
    mse_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')
    mse_mean = -mse_scores.mean()  # Convert to positive MSE
    rmse_mean = np.sqrt(mse_mean)  # Calculate mean RMSE
    results[name] = {'MSE': mse_mean, 'RMSE': rmse_mean}

# Display results
for model_name, metrics in results.items():
    print(f"{model_name}: MSE = {metrics['MSE']:.2f}, RMSE = {metrics['RMSE']:.2f}")

from sklearn.cluster import KMeans
import numpy as np

# Normalize the data ---only selecting the main pollutants
normalized_data = city_air_quality_df.groupby('City')[['CO', 'PM2.5',  'SO2' , 'NO2', 'PM10']].mean()
normalized_data = (normalized_data - normalized_data.mean()) / normalized_data.std()

# Apply KMeans clustering
kmeans = KMeans(n_clusters=5, random_state=0).fit(normalized_data)
normalized_data['Cluster'] = kmeans.labels_

# Display cluster results
print(normalized_data.sort_values('Cluster'))

import matplotlib.pyplot as plt

# Convert Date to datetime if not already done
city_air_quality_df['Date'] = pd.to_datetime(city_air_quality_df['Date'])

# Select only numeric columns (pollutants) for resampling
pollutants = ['PM2.5', 'PM10',  'NO2',  'CO', 'SO2']

# Resample the numeric columns by year and compute the mean
pollutant_trends = city_air_quality_df.set_index('Date')[pollutants].resample('Y').mean()


plt.figure(figsize=(14, 8))

for pollutant in pollutants:
    plt.plot(pollutant_trends.index.year, pollutant_trends[pollutant], label=pollutant)

plt.title('Trend of Principal Pollutants from 2015 to 2020')
plt.xlabel('Year')
plt.ylabel('Pollutant Levels (µg/m³)')
plt.legend()
plt.grid(True)
plt.show()